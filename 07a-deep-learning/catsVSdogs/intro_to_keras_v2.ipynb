{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data-x](http://oi64.tinypic.com/o858n4.jpg)\n",
    "\n",
    "\n",
    "# Intro to Deep Learning with Keras\n",
    "\n",
    "#### Author: Alexander Fred Ojala & Ikhlaq Sidhu\n",
    "\n",
    "_____\n",
    "\n",
    "# Why Keras\n",
    "Modular, powerful and intuitive Deep Learning python library built on TensorFlow, CNTK, Theano.\n",
    "* Minimalist, user-friendly interface\n",
    "* CPUs and GPUs\n",
    "* Open-source, developed and maintained by a community of contributors, and\n",
    "publicly hosted on github\n",
    "* Extremely well documented, lots of working examples: https://keras.io/\n",
    "* Very shallow learning curve â€”> it is by far one of the best tools for both beginners and experts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High level wrappers\n",
    "Compile code down to the deep learning framework (i.e. takes longer to run). See comparison of speed for different DL frameworks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='imgs/train_times.png' width=600></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Suppress TensorFlow and Keras warnings for cleaner output\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras backend\n",
    "\n",
    "We want Keras to use Tensorflow as a backend. If the warning above does not say:\n",
    "\n",
    "<div class='alert alert-danger'>**Using TensorFlow backend.**</div>\n",
    "\n",
    "Then open up the keras configuration file located in:\n",
    "\n",
    "`$HOME/.keras/keras.json` \n",
    "\n",
    "(On Windows replace `$HOME` with `%USERPROFILE%`)\n",
    "\n",
    "and change the entries in the JSON file to:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"floatx\": \"float32\",\n",
    "    \"epsilon\": 1e-07,\n",
    "    \"backend\": \"tensorflow\",\n",
    "    \"image_data_format\": \"channels_last\"\n",
    "}\n",
    "```\n",
    "\n",
    "After that restart your Kernel and run the code again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras \"Hello World\" on Iris\n",
    "\n",
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Plants Database\n",
      "====================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ===================\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR[:980])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data['data']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode y\n",
    "import pandas as pd\n",
    "\n",
    "y = pd.get_dummies(y).values\n",
    "y[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, test_size=0.4,\n",
    "                                                    random_state=1337,\n",
    "                                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4)\n",
      "(90, 3)\n",
      "(60, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Sequential model\n",
    "The simplest model in Keras is the Sequential model, a linear stack of layers.\n",
    "\n",
    "* **Sequential model** linear stack of layers: It allows us to build NNs like legos, by adding one layer on top of the other, swapping layers in and out\n",
    "\n",
    "* Graph: multi-input, multi-output, with arbitrary connections inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Core data structure in Keras is a model\n",
    "# The model is an object in which we organize layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model initialization\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential() # instantiate empty Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import layer classes and stack layers (in an NN model for example), by using `.add()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying the input shape\n",
    "\n",
    "The model needs to know what input shape it should expect. For this reason, the first layer in a  Sequential model needs to receive information about its input shape. There are several possible ways to do this:\n",
    "\n",
    "* Pass an input_shape argument to the first layer. This is a shape tuple (a tuple of integers or None entries, where None indicates that any positive integer may be expected).\n",
    "* Some 2D layers, such as Dense, support the specification of their input shape via the argument  input_dim, and some 3D temporal layers support the arguments input_dim and input_length.\n",
    "\n",
    "\n",
    "* **The following snippets are strictly equivalent:**\n",
    "* model.add(Dense(32, input_shape=(784,)))\n",
    "* model.add(Dense(32, input_dim=784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model contruction (architecture build computational graph)\n",
    "from keras.layers import Dense\n",
    "\n",
    "model.add( Dense(units=64, activation='relu', input_shape=(4,) ))\n",
    "model.add( Dense(units=3, activation='softmax') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation phase, specify learning process\n",
    "\n",
    "Run `.compile()` on the model to specify learning process.\n",
    "\n",
    "Before training a model, you need to configure the learning process, which is done via the  compile method. It receives three arguments:\n",
    "\n",
    "* **An optimizer:** This could be the string identifier of an existing optimizer (such as rmsprop or adagrad), or an instance of the Optimizer class.\n",
    "* **A loss function:** This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function (such as categorical_crossentropy or mse), or it can be an objective function.\n",
    "* **(Optional) A list of metrics:** For any classification problem you will want to set this to metrics=['accuracy']. A metric could be the string identifier of an existing metric or a custom metric function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can also specify our own optimizer or loss function\n",
    "\n",
    "```python\n",
    "# or with we can specify loss function\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = SGD(lr=0.001, momentum = 0.9, nesterov=True),\n",
    "             metrics = ['accuracy'])\n",
    "```\n",
    "\n",
    "### Different optimizers and their trade-offs\n",
    "To read more about gradient descent optimizers, hyperparameters etc. This is a recommended reading: http://ruder.io/optimizing-gradient-descent/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Keras models are trained on Numpy arrays of input data and labels. For training a model, you will typically use the fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 1.2842 - acc: 0.3778\n",
      "Epoch 2/50\n",
      "90/90 [==============================] - 0s 134us/step - loss: 1.1688 - acc: 0.3778\n",
      "Epoch 3/50\n",
      "90/90 [==============================] - 0s 129us/step - loss: 1.0924 - acc: 0.3778\n",
      "Epoch 4/50\n",
      "90/90 [==============================] - 0s 116us/step - loss: 1.0399 - acc: 0.3556\n",
      "Epoch 5/50\n",
      "90/90 [==============================] - 0s 131us/step - loss: 1.0059 - acc: 0.0889\n",
      "Epoch 6/50\n",
      "90/90 [==============================] - 0s 133us/step - loss: 0.9867 - acc: 0.3111\n",
      "Epoch 7/50\n",
      "90/90 [==============================] - 0s 177us/step - loss: 0.9621 - acc: 0.3556\n",
      "Epoch 8/50\n",
      "90/90 [==============================] - 0s 144us/step - loss: 0.9392 - acc: 0.3556\n",
      "Epoch 9/50\n",
      "90/90 [==============================] - 0s 149us/step - loss: 0.9144 - acc: 0.4111\n",
      "Epoch 10/50\n",
      "90/90 [==============================] - 0s 218us/step - loss: 0.8901 - acc: 0.5778\n",
      "Epoch 11/50\n",
      "90/90 [==============================] - 0s 211us/step - loss: 0.8650 - acc: 0.6222\n",
      "Epoch 12/50\n",
      "90/90 [==============================] - 0s 271us/step - loss: 0.8429 - acc: 0.6222\n",
      "Epoch 13/50\n",
      "90/90 [==============================] - 0s 244us/step - loss: 0.8245 - acc: 0.5222\n",
      "Epoch 14/50\n",
      "90/90 [==============================] - 0s 281us/step - loss: 0.8048 - acc: 0.4333\n",
      "Epoch 15/50\n",
      "90/90 [==============================] - 0s 251us/step - loss: 0.7885 - acc: 0.4889\n",
      "Epoch 16/50\n",
      "90/90 [==============================] - 0s 279us/step - loss: 0.7721 - acc: 0.6000\n",
      "Epoch 17/50\n",
      "90/90 [==============================] - 0s 252us/step - loss: 0.7564 - acc: 0.6889\n",
      "Epoch 18/50\n",
      "90/90 [==============================] - 0s 446us/step - loss: 0.7412 - acc: 0.7667\n",
      "Epoch 19/50\n",
      "90/90 [==============================] - 0s 192us/step - loss: 0.7267 - acc: 0.7222\n",
      "Epoch 20/50\n",
      "90/90 [==============================] - 0s 140us/step - loss: 0.7131 - acc: 0.6444\n",
      "Epoch 21/50\n",
      "90/90 [==============================] - 0s 126us/step - loss: 0.7001 - acc: 0.6222\n",
      "Epoch 22/50\n",
      "90/90 [==============================] - 0s 195us/step - loss: 0.6879 - acc: 0.6222\n",
      "Epoch 23/50\n",
      "90/90 [==============================] - 0s 119us/step - loss: 0.6765 - acc: 0.6222\n",
      "Epoch 24/50\n",
      "90/90 [==============================] - 0s 557us/step - loss: 0.6649 - acc: 0.6222\n",
      "Epoch 25/50\n",
      "90/90 [==============================] - 0s 170us/step - loss: 0.6551 - acc: 0.6222\n",
      "Epoch 26/50\n",
      "90/90 [==============================] - 0s 282us/step - loss: 0.6462 - acc: 0.6222\n",
      "Epoch 27/50\n",
      "90/90 [==============================] - 0s 356us/step - loss: 0.6357 - acc: 0.6222\n",
      "Epoch 28/50\n",
      "90/90 [==============================] - 0s 70us/step - loss: 0.6269 - acc: 0.6222\n",
      "Epoch 29/50\n",
      "90/90 [==============================] - 0s 522us/step - loss: 0.6180 - acc: 0.6556\n",
      "Epoch 30/50\n",
      "90/90 [==============================] - 0s 240us/step - loss: 0.6109 - acc: 0.8000\n",
      "Epoch 31/50\n",
      "90/90 [==============================] - 0s 73us/step - loss: 0.6015 - acc: 0.9111\n",
      "Epoch 32/50\n",
      "90/90 [==============================] - 0s 82us/step - loss: 0.5903 - acc: 0.9333\n",
      "Epoch 33/50\n",
      "90/90 [==============================] - 0s 88us/step - loss: 0.5811 - acc: 0.9556\n",
      "Epoch 34/50\n",
      "90/90 [==============================] - 0s 94us/step - loss: 0.5735 - acc: 0.9556\n",
      "Epoch 35/50\n",
      "90/90 [==============================] - 0s 102us/step - loss: 0.5664 - acc: 0.9444\n",
      "Epoch 36/50\n",
      "90/90 [==============================] - 0s 92us/step - loss: 0.5602 - acc: 0.9333\n",
      "Epoch 37/50\n",
      "90/90 [==============================] - 0s 102us/step - loss: 0.5542 - acc: 0.9222\n",
      "Epoch 38/50\n",
      "90/90 [==============================] - 0s 80us/step - loss: 0.5486 - acc: 0.8667\n",
      "Epoch 39/50\n",
      "90/90 [==============================] - 0s 82us/step - loss: 0.5436 - acc: 0.8778\n",
      "Epoch 40/50\n",
      "90/90 [==============================] - 0s 102us/step - loss: 0.5384 - acc: 0.8778\n",
      "Epoch 41/50\n",
      "90/90 [==============================] - 0s 93us/step - loss: 0.5329 - acc: 0.8889\n",
      "Epoch 42/50\n",
      "90/90 [==============================] - 0s 87us/step - loss: 0.5280 - acc: 0.9000\n",
      "Epoch 43/50\n",
      "90/90 [==============================] - 0s 119us/step - loss: 0.5230 - acc: 0.9444\n",
      "Epoch 44/50\n",
      "90/90 [==============================] - 0s 93us/step - loss: 0.5182 - acc: 0.9444\n",
      "Epoch 45/50\n",
      "90/90 [==============================] - 0s 83us/step - loss: 0.5135 - acc: 0.9444\n",
      "Epoch 46/50\n",
      "90/90 [==============================] - 0s 139us/step - loss: 0.5087 - acc: 0.9444\n",
      "Epoch 47/50\n",
      "90/90 [==============================] - 0s 112us/step - loss: 0.5045 - acc: 0.9444\n",
      "Epoch 48/50\n",
      "90/90 [==============================] - 0s 99us/step - loss: 0.5006 - acc: 0.9111\n",
      "Epoch 49/50\n",
      "90/90 [==============================] - 0s 108us/step - loss: 0.4956 - acc: 0.9222\n",
      "Epoch 50/50\n",
      "90/90 [==============================] - 0s 142us/step - loss: 0.4915 - acc: 0.9444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f17de10bda0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model by iterating over the training data in batches\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 50, batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98333334922790527"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Evaluate the model Accuracy on test set\n",
    "model.evaluate(X_test, y_test, batch_size=60,verbose=False)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predictions on new data:\n",
    "\n",
    "class_probabilities = model.predict(X_test, batch_size=128)\n",
    "\n",
    "# gives output of the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06546466,  0.51947147,  0.41506392],\n",
       "       [ 0.86149263,  0.10778557,  0.0307218 ],\n",
       "       [ 0.01215913,  0.42423522,  0.56360573],\n",
       "       [ 0.80053008,  0.15302773,  0.04644221],\n",
       "       [ 0.00811442,  0.36970603,  0.62217957]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_probabilities[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras DNN on MNIST\n",
    "\n",
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "img_dim = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_dim)\n",
    "X_test = X_test.reshape(X_test.shape[0], 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sequential model to stack layers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model contruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize model constructor\n",
    "model = Sequential()\n",
    "# Add layers sequentially\n",
    "model.add(Dense(300, activation=tf.nn.leaky_relu, input_shape=(784,) ) )\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "# Second..\n",
    "model.add(Dense(200, activation=tf.nn.leaky_relu))\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "# Third..\n",
    "model.add(Dense(100, activation=tf.nn.leaky_relu))\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 316,810\n",
      "Trainable params: 316,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a multi-class classification problem\n",
    "model.compile(optimizer='adam', #chooses suitable learning rate for you.\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.2937 - acc: 0.9112\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.1339 - acc: 0.9587\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0972 - acc: 0.9695\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.0769 - acc: 0.9758\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=4, batch_size=128,\n",
    "                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0813915287709\n",
      "Test accuracy: 0.9755\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f17de10bb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(4),history.history['acc'])\n",
    "plt.title('accuracy per iteration')\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Great accuracy for an ANN in so few training steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN in Keras\n",
    "## 99.5% accuracy on MNIST in 12 epochs\n",
    "\n",
    "Note this takes ~1hr to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# notice that we don't flatten image\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "#normalize\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Almost LeNet architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
